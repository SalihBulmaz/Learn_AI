{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a674cb",
   "metadata": {},
   "source": [
    "# Scikit-learn İleri Seviye Ödevleri\n",
    "\n",
    "Bu ödevler, Scikit-learn'ün tüm özelliklerini test etmek ve gerçek dünya makine öğrenmesi problemlerini çözmek için tasarlanmıştır. Her ödev, farklı ML kavramlarını birleştirerek endüstriyel senaryoları simüle eder.\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev 1: Kredi Risk Değerlendirme Sistemi\n",
    "\n",
    "### Açıklama\n",
    "Bir banka için kredi başvurularını değerlendiren makine öğrenmesi sistemi geliştirin. Sistem, başvuranların kredi riskini analiz edecek ve kredi verilip verilmeyeceğine karar verecek.\n",
    "\n",
    "### Gereksinimler\n",
    "- Gerçekçi kredi veri seti oluşturun\n",
    "- Veri preprocessing ve feature engineering yapın\n",
    "- Farklı classification algoritmaları deneyin\n",
    "- Model performansını değerlendirin\n",
    "- Feature importance analizi yapın\n",
    "- Model interpretability sağlayın\n",
    "\n",
    "### Template Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seed ayarlama\n",
    "np.random.seed(42)\n",
    "\n",
    "# ===== VERİ SETİ OLUŞTURMA =====\n",
    "n_samples = 10000\n",
    "\n",
    "# Gerçekçi kredi veri seti\n",
    "data = {\n",
    "    'age': np.random.normal(35, 10, n_samples),\n",
    "    'income': np.random.lognormal(10, 0.5, n_samples),\n",
    "    'credit_score': np.random.normal(650, 100, n_samples),\n",
    "    'employment_years': np.random.exponential(5, n_samples),\n",
    "    'debt_to_income': np.random.beta(2, 5, n_samples),\n",
    "    'loan_amount': np.random.lognormal(11, 0.3, n_samples),\n",
    "    'education': np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], \n",
    "                                n_samples, p=[0.3, 0.4, 0.2, 0.1]),\n",
    "    'marital_status': np.random.choice(['Single', 'Married', 'Divorced'], \n",
    "                                     n_samples, p=[0.4, 0.4, 0.2]),\n",
    "    'home_ownership': np.random.choice(['Rent', 'Own', 'Mortgage'], \n",
    "                                     n_samples, p=[0.4, 0.2, 0.4]),\n",
    "    'purpose': np.random.choice(['Home', 'Car', 'Business', 'Education', 'Other'], \n",
    "                              n_samples, p=[0.3, 0.2, 0.2, 0.1, 0.2])\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Kredi riski hesaplama (gerçekçi kurallar)\n",
    "def calculate_credit_risk(row):\n",
    "    risk_score = 0\n",
    "    \n",
    "    # Yaş faktörü\n",
    "    if row['age'] < 25 or row['age'] > 65:\n",
    "        risk_score += 2\n",
    "    elif 30 <= row['age'] <= 50:\n",
    "        risk_score -= 1\n",
    "    \n",
    "    # Gelir faktörü\n",
    "    if row['income'] < 30000:\n",
    "        risk_score += 3\n",
    "    elif row['income'] > 100000:\n",
    "        risk_score -= 2\n",
    "    \n",
    "    # Kredi skoru\n",
    "    if row['credit_score'] < 600:\n",
    "        risk_score += 4\n",
    "    elif row['credit_score'] > 750:\n",
    "        risk_score -= 2\n",
    "    \n",
    "    # Borç-gelir oranı\n",
    "    if row['debt_to_income'] > 0.4:\n",
    "        risk_score += 3\n",
    "    elif row['debt_to_income'] < 0.2:\n",
    "        risk_score -= 1\n",
    "    \n",
    "    # İstihdam yılı\n",
    "    if row['employment_years'] < 2:\n",
    "        risk_score += 2\n",
    "    \n",
    "    # Eğitim\n",
    "    if row['education'] == 'PhD':\n",
    "        risk_score -= 1\n",
    "    elif row['education'] == 'High School':\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Ev sahipliği\n",
    "    if row['home_ownership'] == 'Own':\n",
    "        risk_score -= 1\n",
    "    elif row['home_ownership'] == 'Rent':\n",
    "        risk_score += 1\n",
    "    \n",
    "    # Rastgele gürültü ekle\n",
    "    risk_score += np.random.normal(0, 0.5)\n",
    "    \n",
    "    return 1 if risk_score > 3 else 0\n",
    "\n",
    "df['credit_risk'] = df.apply(calculate_credit_risk, axis=1)\n",
    "\n",
    "print(f\"Veri seti boyutu: {df.shape}\")\n",
    "print(f\"Kredi riski dağılımı:\\n{df['credit_risk'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ===== BURADA KODUNUZ BAŞLIYOR =====\n",
    "\n",
    "# 1. Veri keşfi ve analizi\n",
    "# Hint: EDA, correlation matrix, distribution plots\n",
    "\n",
    "# 2. Veri preprocessing\n",
    "# Hint: Missing values, encoding, scaling\n",
    "\n",
    "# 3. Feature engineering\n",
    "# Hint: Yeni özellikler oluşturun (örn: income/loan_ratio)\n",
    "\n",
    "# 4. Model seçimi ve eğitimi\n",
    "# Hint: Logistic Regression, Random Forest, SVM, Gradient Boosting\n",
    "\n",
    "# 5. Hyperparameter tuning\n",
    "# Hint: GridSearchCV veya RandomizedSearchCV\n",
    "\n",
    "# 6. Model değerlendirme\n",
    "# Hint: Cross-validation, ROC-AUC, precision-recall\n",
    "\n",
    "# 7. Feature importance analizi\n",
    "# Hint: Model coefficients, feature importance\n",
    "\n",
    "# 8. Model interpretability\n",
    "# Hint: SHAP values, partial dependence plots\n",
    "\n",
    "# 9. Ensemble methods\n",
    "# Hint: Voting classifier, stacking\n",
    "\n",
    "# 10. Sonuçları raporlayın ve öneriler sunun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5042b",
   "metadata": {},
   "source": [
    "### Beklenen Çıktılar\n",
    "- EDA raporu ve görselleştirmeler\n",
    "- Preprocessing pipeline\n",
    "- Model performans karşılaştırması\n",
    "- Feature importance grafikleri\n",
    "- ROC ve precision-recall eğrileri\n",
    "- Model interpretability analizi\n",
    "- Kredi risk değerlendirme önerileri\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev 2: Müşteri Segmentasyonu ve Churn Prediction\n",
    "\n",
    "### Açıklama\n",
    "Bir telekomünikasyon şirketi için müşteri segmentasyonu ve churn prediction sistemi geliştirin. Sistem, müşterileri segmentlere ayıracak ve hangi müşterilerin ayrılma riski taşıdığını tahmin edecek.\n",
    "\n",
    "### Gereksinimler\n",
    "- Müşteri veri seti oluşturun\n",
    "- Unsupervised learning ile segmentasyon yapın\n",
    "- Supervised learning ile churn prediction yapın\n",
    "- Customer lifetime value hesaplayın\n",
    "- Retention stratejileri önerin\n",
    "\n",
    "### Template Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seed ayarlama\n",
    "np.random.seed(42)\n",
    "\n",
    "# ===== MÜŞTERİ VERİ SETİ OLUŞTURMA =====\n",
    "n_customers = 5000\n",
    "\n",
    "# Müşteri özellikleri\n",
    "customer_data = {\n",
    "    'customer_id': range(1, n_customers + 1),\n",
    "    'age': np.random.normal(45, 15, n_customers),\n",
    "    'monthly_charges': np.random.lognormal(4, 0.3, n_customers),\n",
    "    'total_charges': np.random.lognormal(8, 0.5, n_customers),\n",
    "    'tenure_months': np.random.exponential(30, n_customers),\n",
    "    'contract_type': np.random.choice(['Month-to-month', 'One year', 'Two year'], \n",
    "                                    n_customers, p=[0.5, 0.3, 0.2]),\n",
    "    'internet_service': np.random.choice(['DSL', 'Fiber optic', 'No'], \n",
    "                                       n_customers, p=[0.3, 0.4, 0.3]),\n",
    "    'payment_method': np.random.choice(['Electronic check', 'Mailed check', \n",
    "                                      'Bank transfer', 'Credit card'], \n",
    "                                     n_customers, p=[0.3, 0.2, 0.25, 0.25]),\n",
    "    'online_security': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                      n_customers, p=[0.3, 0.4, 0.3]),\n",
    "    'tech_support': np.random.choice(['Yes', 'No', 'No internet service'], \n",
    "                                   n_customers, p=[0.2, 0.5, 0.3]),\n",
    "    'monthly_gb_download': np.random.exponential(50, n_customers),\n",
    "    'customer_service_calls': np.random.poisson(2, n_customers)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(customer_data)\n",
    "\n",
    "# Churn hesaplama (gerçekçi kurallar)\n",
    "def calculate_churn(row):\n",
    "    churn_prob = 0\n",
    "    \n",
    "    # Sözleşme türü\n",
    "    if row['contract_type'] == 'Month-to-month':\n",
    "        churn_prob += 0.3\n",
    "    elif row['contract_type'] == 'One year':\n",
    "        churn_prob += 0.1\n",
    "    else:  # Two year\n",
    "        churn_prob += 0.05\n",
    "    \n",
    "    # Müşteri hizmetleri çağrıları\n",
    "    if row['customer_service_calls'] > 3:\n",
    "        churn_prob += 0.2\n",
    "    \n",
    "    # Tenure (müşteri sadakati)\n",
    "    if row['tenure_months'] < 12:\n",
    "        churn_prob += 0.15\n",
    "    elif row['tenure_months'] > 60:\n",
    "        churn_prob -= 0.1\n",
    "    \n",
    "    # Aylık ücret\n",
    "    if row['monthly_charges'] > 80:\n",
    "        churn_prob += 0.1\n",
    "    \n",
    "    # İnternet hizmeti\n",
    "    if row['internet_service'] == 'Fiber optic':\n",
    "        churn_prob += 0.05  # Daha pahalı\n",
    "    \n",
    "    # Rastgele faktör\n",
    "    churn_prob += np.random.normal(0, 0.1)\n",
    "    \n",
    "    return 1 if churn_prob > 0.3 else 0\n",
    "\n",
    "df['churn'] = df.apply(calculate_churn, axis=1)\n",
    "\n",
    "# Customer Lifetime Value hesaplama\n",
    "df['clv'] = df['monthly_charges'] * df['tenure_months'] * (1 - df['churn'] * 0.5)\n",
    "\n",
    "print(f\"Müşteri veri seti boyutu: {df.shape}\")\n",
    "print(f\"Churn oranı: {df['churn'].mean():.3f}\")\n",
    "\n",
    "# ===== BURADA KODUNUZ BAŞLIYOR =====\n",
    "\n",
    "# 1. Veri keşfi ve analizi\n",
    "# Hint: Churn analizi, CLV analizi, correlation matrix\n",
    "\n",
    "# 2. Müşteri segmentasyonu (Unsupervised Learning)\n",
    "# Hint: K-Means, DBSCAN, PCA ile boyut azaltma\n",
    "\n",
    "# 3. Segment analizi\n",
    "# Hint: Her segmentin özelliklerini analiz edin\n",
    "\n",
    "# 4. Churn prediction (Supervised Learning)\n",
    "# Hint: Feature engineering, model seçimi\n",
    "\n",
    "# 5. Model performans değerlendirme\n",
    "# Hint: Cross-validation, ROC-AUC, precision-recall\n",
    "\n",
    "# 6. Feature importance analizi\n",
    "# Hint: Churn'a en çok etki eden faktörler\n",
    "\n",
    "# 7. Customer Lifetime Value prediction\n",
    "# Hint: Regression model ile CLV tahmini\n",
    "\n",
    "# 8. Retention stratejileri\n",
    "# Hint: Riskli müşteriler için öneriler\n",
    "\n",
    "# 9. Anomaly detection\n",
    "# Hint: Anormal müşteri davranışlarını tespit edin\n",
    "\n",
    "# 10. Sonuçları raporlayın ve iş önerileri sunun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c034f8",
   "metadata": {},
   "source": [
    "### Beklenen Çıktılar\n",
    "- Müşteri segmentasyonu grafikleri\n",
    "- Churn prediction model performansı\n",
    "- CLV analizi ve tahminleri\n",
    "- Feature importance analizi\n",
    "- Retention stratejileri önerileri\n",
    "- Anomaly detection sonuçları\n",
    "- İş raporu ve öneriler\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev 3: E-ticaret Ürün Öneri Sistemi\n",
    "\n",
    "### Açıklama\n",
    "Bir e-ticaret platformu için ürün öneri sistemi geliştirin. Sistem, collaborative filtering ve content-based filtering yöntemlerini kullanarak kişiselleştirilmiş öneriler sunacak.\n",
    "\n",
    "### Gereksinimler\n",
    "- Kullanıcı-ürün etkileşim verisi oluşturun\n",
    "- Collaborative filtering implementasyonu\n",
    "- Content-based filtering implementasyonu\n",
    "- Hybrid recommendation sistemi\n",
    "- Öneri kalitesini değerlendirin\n",
    "\n",
    "### Template Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b959ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seed ayarlama\n",
    "np.random.seed(42)\n",
    "\n",
    "# ===== E-TİCARET VERİ SETİ OLUŞTURMA =====\n",
    "n_users = 1000\n",
    "n_products = 500\n",
    "n_interactions = 10000\n",
    "\n",
    "# Kullanıcı verileri\n",
    "users = pd.DataFrame({\n",
    "    'user_id': range(1, n_users + 1),\n",
    "    'age': np.random.normal(35, 12, n_users),\n",
    "    'gender': np.random.choice(['M', 'F'], n_users),\n",
    "    'location': np.random.choice(['Istanbul', 'Ankara', 'Izmir', 'Bursa'], n_users),\n",
    "    'membership_days': np.random.exponential(365, n_users)\n",
    "})\n",
    "\n",
    "# Ürün verileri\n",
    "categories = ['Electronics', 'Clothing', 'Books', 'Home', 'Sports', 'Beauty', 'Food', 'Toys']\n",
    "subcategories = {\n",
    "    'Electronics': ['Smartphones', 'Laptops', 'Tablets', 'Accessories'],\n",
    "    'Clothing': ['Men', 'Women', 'Kids', 'Shoes'],\n",
    "    'Books': ['Fiction', 'Non-fiction', 'Academic', 'Children'],\n",
    "    'Home': ['Furniture', 'Kitchen', 'Garden', 'Decor'],\n",
    "    'Sports': ['Fitness', 'Outdoor', 'Team Sports', 'Equipment'],\n",
    "    'Beauty': ['Skincare', 'Makeup', 'Haircare', 'Fragrances'],\n",
    "    'Food': ['Snacks', 'Beverages', 'Organic', 'International'],\n",
    "    'Toys': ['Educational', 'Action Figures', 'Board Games', 'Puzzles']\n",
    "}\n",
    "\n",
    "products = []\n",
    "for i in range(n_products):\n",
    "    category = np.random.choice(categories)\n",
    "    subcategory = np.random.choice(subcategories[category])\n",
    "    \n",
    "    products.append({\n",
    "        'product_id': i + 1,\n",
    "        'name': f\"Product_{i+1}\",\n",
    "        'category': category,\n",
    "        'subcategory': subcategory,\n",
    "        'price': np.random.lognormal(3, 0.5),\n",
    "        'rating': np.random.normal(4, 0.5),\n",
    "        'review_count': np.random.poisson(50),\n",
    "        'description': f\"Great {subcategory.lower()} product in {category.lower()} category\"\n",
    "    })\n",
    "\n",
    "products_df = pd.DataFrame(products)\n",
    "\n",
    "# Kullanıcı-ürün etkileşimleri\n",
    "interactions = []\n",
    "for _ in range(n_interactions):\n",
    "    user_id = np.random.randint(1, n_users + 1)\n",
    "    product_id = np.random.randint(1, n_products + 1)\n",
    "    \n",
    "    # Kullanıcı ve ürün uyumluluğu\n",
    "    user = users.iloc[user_id - 1]\n",
    "    product = products_df.iloc[product_id - 1]\n",
    "    \n",
    "    # Rating hesaplama (gerçekçi)\n",
    "    base_rating = product['rating']\n",
    "    \n",
    "    # Yaş faktörü\n",
    "    if user['age'] < 25 and product['category'] in ['Electronics', 'Sports']:\n",
    "        base_rating += 0.5\n",
    "    elif user['age'] > 50 and product['category'] in ['Home', 'Books']:\n",
    "        base_rating += 0.3\n",
    "    \n",
    "    # Cinsiyet faktörü\n",
    "    if user['gender'] == 'F' and product['category'] in ['Beauty', 'Clothing']:\n",
    "        base_rating += 0.4\n",
    "    elif user['gender'] == 'M' and product['category'] in ['Electronics', 'Sports']:\n",
    "        base_rating += 0.3\n",
    "    \n",
    "    # Rastgele gürültü\n",
    "    final_rating = np.clip(base_rating + np.random.normal(0, 0.5), 1, 5)\n",
    "    \n",
    "    interactions.append({\n",
    "        'user_id': user_id,\n",
    "        'product_id': product_id,\n",
    "        'rating': final_rating,\n",
    "        'timestamp': np.random.randint(1, 1000)\n",
    "    })\n",
    "\n",
    "interactions_df = pd.DataFrame(interactions)\n",
    "\n",
    "print(f\"Kullanıcı sayısı: {n_users}\")\n",
    "print(f\"Ürün sayısı: {n_products}\")\n",
    "print(f\"Etkileşim sayısı: {len(interactions_df)}\")\n",
    "\n",
    "# ===== BURADA KODUNUZ BAŞLIYOR =====\n",
    "\n",
    "# 1. Veri analizi ve keşfi\n",
    "# Hint: Rating dağılımı, kullanıcı-ürün matrisi\n",
    "\n",
    "# 2. Collaborative Filtering (User-based)\n",
    "# Hint: Cosine similarity, kullanıcı benzerliği\n",
    "\n",
    "# 3. Collaborative Filtering (Item-based)\n",
    "# Hint: Ürün benzerliği, item-item matrix\n",
    "\n",
    "# 4. Matrix Factorization\n",
    "# Hint: SVD, NMF ile latent factors\n",
    "\n",
    "# 5. Content-based Filtering\n",
    "# Hint: TF-IDF, ürün özellikleri\n",
    "\n",
    "# 6. Hybrid Recommendation\n",
    "# Hint: Collaborative + Content-based kombinasyonu\n",
    "\n",
    "# 7. Öneri kalitesi değerlendirme\n",
    "# Hint: Precision@k, Recall@k, NDCG\n",
    "\n",
    "# 8. Cold start problemi çözümü\n",
    "# Hint: Yeni kullanıcılar/ürünler için stratejiler\n",
    "\n",
    "# 9. A/B testing simülasyonu\n",
    "# Hint: Farklı öneri algoritmalarını karşılaştırın\n",
    "\n",
    "# 10. Sonuçları raporlayın ve öneri sistemi analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e95dc",
   "metadata": {},
   "source": [
    "### Beklenen Çıktılar\n",
    "- Kullanıcı-ürün etkileşim matrisi\n",
    "- Collaborative filtering sonuçları\n",
    "- Content-based filtering sonuçları\n",
    "- Hybrid öneri sistemi performansı\n",
    "- Öneri kalitesi metrikleri\n",
    "- Cold start çözümleri\n",
    "- A/B testing sonuçları\n",
    "- Öneri sistemi analiz raporu\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev 4: Zaman Serisi Tahmin Sistemi\n",
    "\n",
    "### Açıklama\n",
    "Bir perakende şirketi için satış tahmin sistemi geliştirin. Sistem, farklı zaman serisi modellerini kullanarak gelecek satışları tahmin edecek ve mevsimsellik analizi yapacak.\n",
    "\n",
    "### Gereksinimler\n",
    "- Zaman serisi veri seti oluşturun\n",
    "- Trend ve mevsimsellik analizi yapın\n",
    "- Farklı forecasting modelleri deneyin\n",
    "- Model performansını değerlendirin\n",
    "- Anomaly detection uygulayın\n",
    "\n",
    "### Template Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fd536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Seed ayarlama\n",
    "np.random.seed(42)\n",
    "\n",
    "# ===== ZAMAN SERİSİ VERİ SETİ OLUŞTURMA =====\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "\n",
    "# Temel trend ve mevsimsellik\n",
    "n_days = len(date_range)\n",
    "trend = np.linspace(100, 200, n_days)  # Yükselen trend\n",
    "\n",
    "# Yıllık mevsimsellik (yaz aylarında artış)\n",
    "seasonal_pattern = np.sin(2 * np.pi * np.arange(n_days) / 365.25) * 30\n",
    "\n",
    "# Haftalık mevsimsellik (hafta sonu artışı)\n",
    "weekly_pattern = np.array([0, 0, 0, 0, 10, 15, 10] * (n_days // 7 + 1))[:n_days]\n",
    "\n",
    "# Tatil etkileri\n",
    "holiday_effects = np.zeros(n_days)\n",
    "holiday_dates = [\n",
    "    '2020-01-01', '2020-05-01', '2020-10-29', '2020-12-25',\n",
    "    '2021-01-01', '2021-05-01', '2021-10-29', '2021-12-25',\n",
    "    '2022-01-01', '2022-05-01', '2022-10-29', '2022-12-25',\n",
    "    '2023-01-01', '2023-05-01', '2023-10-29', '2023-12-25'\n",
    "]\n",
    "\n",
    "for holiday in holiday_dates:\n",
    "    holiday_idx = (pd.to_datetime(holiday) - start_date).days\n",
    "    if 0 <= holiday_idx < n_days:\n",
    "        holiday_effects[holiday_idx] = 20\n",
    "\n",
    "# Promosyon etkileri (rastgele)\n",
    "promotion_effects = np.zeros(n_days)\n",
    "promotion_days = np.random.choice(n_days, size=50, replace=False)\n",
    "promotion_effects[promotion_days] = np.random.uniform(10, 30, len(promotion_days))\n",
    "\n",
    "# Rastgele gürültü\n",
    "noise = np.random.normal(0, 5, n_days)\n",
    "\n",
    "# Toplam satış\n",
    "sales = trend + seasonal_pattern + weekly_pattern + holiday_effects + promotion_effects + noise\n",
    "sales = np.maximum(sales, 0)  # Negatif satış olmaz\n",
    "\n",
    "# Veri seti oluşturma\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales,\n",
    "    'year': date_range.year,\n",
    "    'month': date_range.month,\n",
    "    'day': date_range.day,\n",
    "    'day_of_week': date_range.dayofweek,\n",
    "    'quarter': date_range.quarter,\n",
    "    'is_weekend': date_range.dayofweek.isin([5, 6]).astype(int),\n",
    "    'is_holiday': (holiday_effects > 0).astype(int),\n",
    "    'is_promotion': (promotion_effects > 0).astype(int)\n",
    "})\n",
    "\n",
    "print(f\"Zaman serisi boyutu: {df.shape}\")\n",
    "print(f\"Satış istatistikleri:\\n{df['sales'].describe()}\")\n",
    "\n",
    "# ===== BURADA KODUNUZ BAŞLIYOR =====\n",
    "\n",
    "# 1. Zaman serisi analizi\n",
    "# Hint: Trend, mevsimsellik, stationarity test\n",
    "\n",
    "# 2. Feature engineering\n",
    "# Hint: Lag features, rolling statistics, seasonal features\n",
    "\n",
    "# 3. Train-test split (zaman bazlı)\n",
    "# Hint: Son 6 ay test için ayırın\n",
    "\n",
    "# 4. Basit modeller\n",
    "# Hint: Linear regression, moving average\n",
    "\n",
    "# 5. Gelişmiş modeller\n",
    "# Hint: Random Forest, XGBoost, LSTM (basit)\n",
    "\n",
    "# 6. Mevsimsellik analizi\n",
    "# Hint: Decomposition, seasonal patterns\n",
    "\n",
    "# 7. Anomaly detection\n",
    "# Hint: Statistical methods, isolation forest\n",
    "\n",
    "# 8. Model performans değerlendirme\n",
    "# Hint: RMSE, MAE, MAPE\n",
    "\n",
    "# 9. Forecasting\n",
    "# Hint: Gelecek 30 gün tahmini\n",
    "\n",
    "# 10. Sonuçları raporlayın ve tahmin analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb8bbb",
   "metadata": {},
   "source": [
    "### Beklenen Çıktılar\n",
    "- Zaman serisi dekompozisyonu\n",
    "- Trend ve mevsimsellik analizi\n",
    "- Model performans karşılaştırması\n",
    "- Forecasting grafikleri\n",
    "- Anomaly detection sonuçları\n",
    "- Tahmin güvenilirlik analizi\n",
    "- Zaman serisi raporu\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev 5: NLP ve Metin Analizi Sistemi\n",
    "\n",
    "### Açıklama\n",
    "Bir sosyal medya platformu için metin analizi sistemi geliştirin. Sistem, sentiment analysis, topic modeling ve text classification yapacak.\n",
    "\n",
    "### Gereksinimler\n",
    "- Metin veri seti oluşturun\n",
    "- Text preprocessing uygulayın\n",
    "- Sentiment analysis yapın\n",
    "- Topic modeling uygulayın\n",
    "- Text classification yapın\n",
    "\n",
    "### Template Kod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e22c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# NLTK data download\n",
    "try:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('vader_lexicon')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Seed ayarlama\n",
    "np.random.seed(42)\n",
    "\n",
    "# ===== METİN VERİ SETİ OLUŞTURMA =====\n",
    "n_samples = 5000\n",
    "\n",
    "# Sentiment kategorileri\n",
    "sentiments = ['positive', 'negative', 'neutral']\n",
    "sentiment_probs = [0.4, 0.3, 0.3]\n",
    "\n",
    "# Konu kategorileri\n",
    "topics = ['technology', 'politics', 'sports', 'entertainment', 'business']\n",
    "topic_probs = [0.25, 0.2, 0.2, 0.2, 0.15]\n",
    "\n",
    "# Pozitif metinler\n",
    "positive_texts = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",\n",
    "    \"Great experience with this service. Highly recommended!\",\n",
    "    \"Excellent quality and fast delivery. Very satisfied!\",\n",
    "    \"This is exactly what I was looking for. Perfect!\",\n",
    "    \"Outstanding performance and great value for money.\",\n",
    "    \"Fantastic customer service and amazing results.\",\n",
    "    \"Wonderful experience, will definitely buy again!\",\n",
    "    \"Superb quality and exceeded my expectations.\",\n",
    "    \"Brilliant design and excellent functionality.\",\n",
    "    \"Outstanding work and professional service.\"\n",
    "]\n",
    "\n",
    "# Negatif metinler\n",
    "negative_texts = [\n",
    "    \"Terrible product, complete waste of money.\",\n",
    "    \"Very disappointed with the quality and service.\",\n",
    "    \"Poor customer support and slow delivery.\",\n",
    "    \"This is the worst purchase I've ever made.\",\n",
    "    \"Awful experience, would not recommend to anyone.\",\n",
    "    \"Bad quality and expensive for what you get.\",\n",
    "    \"Frustrated with the poor performance.\",\n",
    "    \"Disappointing results and waste of time.\",\n",
    "    \"Terrible design and difficult to use.\",\n",
    "    \"Horrible service and unprofessional staff.\"\n",
    "]\n",
    "\n",
    "# Nötr metinler\n",
    "neutral_texts = [\n",
    "    \"The product arrived on time as expected.\",\n",
    "    \"Standard quality and average performance.\",\n",
    "    \"It works as described in the specifications.\",\n",
    "    \"Normal delivery time and acceptable quality.\",\n",
    "    \"The service meets basic requirements.\",\n",
    "    \"Average experience, nothing special.\",\n",
    "    \"Product functions as advertised.\",\n",
    "    \"Standard features and typical performance.\",\n",
    "    \"Regular quality and expected results.\",\n",
    "    \"Basic functionality and normal operation.\"\n",
    "]\n",
    "\n",
    "# Konu bazlı kelimeler\n",
    "topic_keywords = {\n",
    "    'technology': ['software', 'hardware', 'computer', 'digital', 'tech', 'app', 'system'],\n",
    "    'politics': ['government', 'policy', 'election', 'democracy', 'vote', 'political'],\n",
    "    'sports': ['game', 'team', 'player', 'match', 'championship', 'sport'],\n",
    "    'entertainment': ['movie', 'music', 'show', 'celebrity', 'film', 'concert'],\n",
    "    'business': ['company', 'market', 'investment', 'profit', 'business', 'finance']\n",
    "}\n",
    "\n",
    "# Metin oluşturma fonksiyonu\n",
    "def generate_text(sentiment, topic):\n",
    "    if sentiment == 'positive':\n",
    "        base_text = np.random.choice(positive_texts)\n",
    "    elif sentiment == 'negative':\n",
    "        base_text = np.random.choice(negative_texts)\n",
    "    else:\n",
    "        base_text = np.random.choice(neutral_texts)\n",
    "    \n",
    "    # Konu kelimelerini ekle\n",
    "    topic_words = topic_keywords[topic]\n",
    "    if np.random.random() > 0.5:\n",
    "        base_text += f\" Related to {np.random.choice(topic_words)}.\"\n",
    "    \n",
    "    # Rastgele değişiklikler\n",
    "    if np.random.random() > 0.8:\n",
    "        base_text += \" \" + np.random.choice([\"Really!\", \"Amazing!\", \"Terrible!\", \"Okay.\"])\n",
    "    \n",
    "    return base_text\n",
    "\n",
    "# Veri seti oluşturma\n",
    "texts = []\n",
    "sentiment_labels = []\n",
    "topic_labels = []\n",
    "\n",
    "for _ in range(n_samples):\n",
    "    sentiment = np.random.choice(sentiments, p=sentiment_probs)\n",
    "    topic = np.random.choice(topics, p=topic_probs)\n",
    "    \n",
    "    text = generate_text(sentiment, topic)\n",
    "    \n",
    "    texts.append(text)\n",
    "    sentiment_labels.append(sentiment)\n",
    "    topic_labels.append(topic)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'sentiment': sentiment_labels,\n",
    "    'topic': topic_labels\n",
    "})\n",
    "\n",
    "print(f\"Metin veri seti boyutu: {df.shape}\")\n",
    "print(f\"Sentiment dağılımı:\\n{df['sentiment'].value_counts()}\")\n",
    "print(f\"Konu dağılımı:\\n{df['topic'].value_counts()}\")\n",
    "\n",
    "# ===== BURADA KODUNUZ BAŞLIYOR =====\n",
    "\n",
    "# 1. Text preprocessing\n",
    "# Hint: Tokenization, stopwords removal, lemmatization\n",
    "\n",
    "# 2. Feature extraction\n",
    "# Hint: TF-IDF, CountVectorizer, word embeddings\n",
    "\n",
    "# 3. Sentiment analysis\n",
    "# Hint: Classification model, VADER sentiment\n",
    "\n",
    "# 4. Topic modeling\n",
    "# Hint: LDA, NMF, topic extraction\n",
    "\n",
    "# 5. Text classification\n",
    "# Hint: Topic classification, multi-class\n",
    "\n",
    "# 6. Model performans değerlendirme\n",
    "# Hint: Accuracy, precision, recall, F1\n",
    "\n",
    "# 7. Feature importance analizi\n",
    "# Hint: Most important words, topics\n",
    "\n",
    "# 8. Word cloud ve görselleştirme\n",
    "# Hint: Word frequency, topic visualization\n",
    "\n",
    "# 9. Cross-validation\n",
    "# Hint: Model stability, generalization\n",
    "\n",
    "# 10. Sonuçları raporlayın ve metin analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e354d4",
   "metadata": {},
   "source": [
    "### Beklenen Çıktılar\n",
    "- Text preprocessing pipeline\n",
    "- Sentiment analysis sonuçları\n",
    "- Topic modeling grafikleri\n",
    "- Classification performansı\n",
    "- Word cloud görselleştirmeleri\n",
    "- Feature importance analizi\n",
    "- Cross-validation sonuçları\n",
    "- NLP analiz raporu\n",
    "\n",
    "---\n",
    "\n",
    "## Ödev Değerlendirme Kriterleri\n",
    "\n",
    "### Her Ödev İçin:\n",
    "1. **Kod Kalitesi** (20%): Temiz, modüler, okunabilir kod\n",
    "2. **Model Performansı** (25%): Doğru metrikler ve yorumlama\n",
    "3. **Analiz Derinliği** (20%): Kapsamlı analiz ve insight'lar\n",
    "4. **Görselleştirme** (15%): Etkili grafikler ve tablolar\n",
    "5. **Teorik Anlayış** (20%): Algoritma ve kavram bilgisi\n",
    "\n",
    "### Bonus Puanlar:\n",
    "- Ek özellikler ve optimizasyonlar\n",
    "- Yaratıcı çözümler\n",
    "- Performans iyileştirmeleri\n",
    "- Dokümantasyon kalitesi\n",
    "\n",
    "### Teslim Formatı:\n",
    "- Jupyter notebook (.ipynb)\n",
    "- Markdown açıklamalar\n",
    "- Kod yorumları\n",
    "- Sonuç analizleri\n",
    "- Görselleştirmeler\n",
    "\n",
    "Her ödev, Scikit-learn'ün farklı yönlerini test eder ve gerçek dünya makine öğrenmesi problemlerini simüle eder. Ödevler zorluk seviyesi artacak şekilde sıralanmıştır. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
